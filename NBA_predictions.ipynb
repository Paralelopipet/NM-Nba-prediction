{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_name</th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>Ortg</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>...</th>\n",
       "      <th>dgbpm</th>\n",
       "      <th>oreb</th>\n",
       "      <th>dreb</th>\n",
       "      <th>treb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>pts</th>\n",
       "      <th>Unnamed: 64</th>\n",
       "      <th>Unnamed: 65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeAndrae Ross</td>\n",
       "      <td>South Alabama</td>\n",
       "      <td>SB</td>\n",
       "      <td>26</td>\n",
       "      <td>29.5</td>\n",
       "      <td>97.3</td>\n",
       "      <td>16.6</td>\n",
       "      <td>42.5</td>\n",
       "      <td>44.43</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.941150</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>1.1923</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>3.8846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.22026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pooh Williams</td>\n",
       "      <td>Utah St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>34</td>\n",
       "      <td>60.9</td>\n",
       "      <td>108.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>52.4</td>\n",
       "      <td>54.48</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247934</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>1.2647</td>\n",
       "      <td>1.9412</td>\n",
       "      <td>1.8235</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>5.9412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.94375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jesus Verdejo</td>\n",
       "      <td>South Florida</td>\n",
       "      <td>BE</td>\n",
       "      <td>27</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>45.7</td>\n",
       "      <td>47.98</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.883163</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2.9630</td>\n",
       "      <td>1.9630</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.1852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.92680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mike Hornbuckle</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>WCC</td>\n",
       "      <td>30</td>\n",
       "      <td>44.5</td>\n",
       "      <td>97.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.69</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393459</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>2.1333</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>4.9333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.77427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Brown</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>BW</td>\n",
       "      <td>33</td>\n",
       "      <td>56.2</td>\n",
       "      <td>96.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>54.31</td>\n",
       "      <td>8.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.668318</td>\n",
       "      <td>1.4242</td>\n",
       "      <td>3.3030</td>\n",
       "      <td>4.7273</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>7.5758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61056</th>\n",
       "      <td>Trey Patterson</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>BE</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>60.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.018200</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Pure PG</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61057</th>\n",
       "      <td>Stavros Polatoglou</td>\n",
       "      <td>Northwestern St.</td>\n",
       "      <td>Slnd</td>\n",
       "      <td>4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.993820</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61058</th>\n",
       "      <td>Sandy Ryan</td>\n",
       "      <td>Tulane</td>\n",
       "      <td>Amer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.126810</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>PF/C</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61059</th>\n",
       "      <td>Ty Larson</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>B12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.380750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>PF/C</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61060</th>\n",
       "      <td>Jaden Jones</td>\n",
       "      <td>Rutgers</td>\n",
       "      <td>B10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.6</td>\n",
       "      <td>28.8</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>10.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.329310</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>Pure PG</td>\n",
       "      <td>10.43920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61061 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              player_name              team  conf  GP  Min_per   Ortg   usg  \\\n",
       "0           DeAndrae Ross     South Alabama    SB  26     29.5   97.3  16.6   \n",
       "1           Pooh Williams          Utah St.   WAC  34     60.9  108.3  14.9   \n",
       "2           Jesus Verdejo     South Florida    BE  27     72.0   96.2  21.8   \n",
       "3         Mike Hornbuckle        Pepperdine   WCC  30     44.5   97.7  16.0   \n",
       "4           Anthony Brown           Pacific    BW  33     56.2   96.5  22.0   \n",
       "...                   ...               ...   ...  ..      ...    ...   ...   \n",
       "61056      Trey Patterson         Villanova    BE   2      0.3   60.5  19.3   \n",
       "61057  Stavros Polatoglou  Northwestern St.  Slnd   4      1.3   28.3   7.1   \n",
       "61058          Sandy Ryan            Tulane  Amer   1      0.1    0.0   0.0   \n",
       "61059           Ty Larson        Texas Tech   B12   1      0.1    0.0   0.0   \n",
       "61060         Jaden Jones           Rutgers   B10   4      1.0   89.6  28.8   \n",
       "\n",
       "        eFG  TS_per  ORB_per  ...      dgbpm    oreb    dreb    treb     ast  \\\n",
       "0      42.5   44.43      1.6  ...  -1.941150  0.1923  0.6154  0.8077  1.1923   \n",
       "1      52.4   54.48      3.8  ...  -0.247934  0.6765  1.2647  1.9412  1.8235   \n",
       "2      45.7   47.98      2.1  ...  -0.883163  0.6296  2.3333  2.9630  1.9630   \n",
       "3      53.6   53.69      4.1  ...  -0.393459  0.7000  1.4333  2.1333  1.1000   \n",
       "4      52.8   54.31      8.3  ...  -0.668318  1.4242  3.3030  4.7273  0.8485   \n",
       "...     ...     ...      ...  ...        ...     ...     ...     ...     ...   \n",
       "61056   0.0    0.00      0.0  ...  16.018200  0.0000  0.0000  0.0000  0.5000   \n",
       "61057   0.0    0.00      7.0  ...  -4.993820  0.2500  0.0000  0.2500  0.0000   \n",
       "61058   0.0    0.00      0.0  ...  -1.126810  0.0000  0.0000  0.0000  0.0000   \n",
       "61059   0.0    0.00      0.0  ...  -2.380750  0.0000  0.0000  0.0000  0.0000   \n",
       "61060  25.0   25.00     10.3  ...  -3.329310  0.2500  0.0000  0.2500  0.7500   \n",
       "\n",
       "          stl     blk      pts  Unnamed: 64  Unnamed: 65  \n",
       "0      0.3462  0.0385   3.8846          NaN      6.22026  \n",
       "1      0.4118  0.2353   5.9412          NaN      3.94375  \n",
       "2      0.4815  0.0000  12.1852          NaN     10.92680  \n",
       "3      0.5667  0.1333   4.9333          NaN      6.77427  \n",
       "4      0.4545  0.3333   7.5758          NaN      0.00000  \n",
       "...       ...     ...      ...          ...          ...  \n",
       "61056  0.5000  0.0000   0.0000      Pure PG      0.00000  \n",
       "61057  0.0000  0.0000   0.0000            C      0.00000  \n",
       "61058  0.0000  0.0000   0.0000         PF/C      0.00000  \n",
       "61059  0.0000  0.0000   0.0000         PF/C      0.00000  \n",
       "61060  0.0000  0.0000   0.7500      Pure PG     10.43920  \n",
       "\n",
       "[61061 rows x 66 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/CollegeBasketballPlayers2009-2021.csv\", low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player_name', 'team', 'conf', 'GP', 'Min_per', 'Ortg', 'usg', 'eFG',\n",
       "       'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM', 'FTA',\n",
       "       'FT_per', 'twoPM', 'twoPA', 'twoP_per', 'TPM', 'TPA', 'TP_per',\n",
       "       'blk_per', 'stl_per', 'ftr', 'yr', 'ht', 'num', 'porpag', 'adjoe',\n",
       "       'pfr', 'year', 'pid', 'type', 'Rec Rank', 'ast/tov', 'rimmade',\n",
       "       'rimmade+rimmiss', 'midmade', 'midmade+midmiss',\n",
       "       'rimmade/(rimmade+rimmiss)', 'midmade/(midmade+midmiss)', 'dunksmade',\n",
       "       'dunksmiss+dunksmade', 'dunksmade/(dunksmade+dunksmiss)', 'pick',\n",
       "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
       "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
       "       'pts', 'Unnamed: 64', 'Unnamed: 65'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biranje atributa\n",
    "\n",
    "U datasetu postoje 66 atributa za svakog igrača, što je previše. Redukcija prostora atributa će biti vršena u tri koraka:\n",
    "\n",
    "1. Izbacivanje redundantnih atributa.  _Primer_: Odnos asistencija i izgubljenih lopti (`ast/tov`) je suvišan kada već postoje atributi za broj asistencije i broj izgubljenih lopti\n",
    "2. Izbacivanje atributa na osnovu iskustvenog zananja. _Primer_: Nepotrebno je da pored škole za koju igra student koristimo kao atribut i konferenciju u kojoj je ta škola\n",
    "3. Nad ostalim atributima će biti izračunata korelacija sa ciljanim izlazima modela, i biće izabrani najboljih 10\n",
    "\n",
    "Ovim postupkom će model biti manji, i samim tim će mu biti smanjena mogućnost overfittovanja.\n",
    "\n",
    "Cilj mreže je predviđanje da li će neki pik biti izabran na draftu. Svi odbirci koji imaju vrednost u `pick` koloni biće označeni kao pozitivni, dok će ostali biti označeni kao negativni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose valuable features\n",
    "clean_df = df[[\"GP\", \"Min_per\", \"usg\", \"eFG\", \"TS_per\", \"ORB_per\", \"DRB_per\", \"AST_per\", \n",
    "               \"TO_per\", \"FT_per\", \"twoP_per\", \"TP_per\", \"blk_per\", \"stl_per\", \"porpag\", \"adjoe\", \"adrtg\", \"bpm\"]].copy()\n",
    "clean_df.dropna(inplace=True)\n",
    "\n",
    "# Calculate target based on if the player was picked in the draft\n",
    "clean_df[\"Target\"] = df[\"pick\"].copy().fillna(0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>AST_per</th>\n",
       "      <th>TO_per</th>\n",
       "      <th>FT_per</th>\n",
       "      <th>twoP_per</th>\n",
       "      <th>TP_per</th>\n",
       "      <th>blk_per</th>\n",
       "      <th>stl_per</th>\n",
       "      <th>porpag</th>\n",
       "      <th>adjoe</th>\n",
       "      <th>adrtg</th>\n",
       "      <th>bpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "      <td>6.101600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.962336e-17</td>\n",
       "      <td>2.198611e-16</td>\n",
       "      <td>7.182751e-16</td>\n",
       "      <td>3.363130e-16</td>\n",
       "      <td>8.943504e-17</td>\n",
       "      <td>2.748264e-17</td>\n",
       "      <td>-1.695539e-16</td>\n",
       "      <td>-4.564913e-17</td>\n",
       "      <td>-1.117938e-16</td>\n",
       "      <td>-4.341326e-16</td>\n",
       "      <td>6.614466e-17</td>\n",
       "      <td>-5.543109e-17</td>\n",
       "      <td>1.164519e-18</td>\n",
       "      <td>-3.330524e-17</td>\n",
       "      <td>4.099106e-17</td>\n",
       "      <td>-4.844398e-17</td>\n",
       "      <td>1.109321e-15</td>\n",
       "      <td>-3.912783e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.148194e+00</td>\n",
       "      <td>-1.324560e+00</td>\n",
       "      <td>-2.903684e+00</td>\n",
       "      <td>-2.420169e+00</td>\n",
       "      <td>-2.705139e+00</td>\n",
       "      <td>-6.028329e-01</td>\n",
       "      <td>-1.191956e+00</td>\n",
       "      <td>-1.156674e+00</td>\n",
       "      <td>-1.644319e+00</td>\n",
       "      <td>-2.129715e+00</td>\n",
       "      <td>-2.184332e+00</td>\n",
       "      <td>-1.194590e+00</td>\n",
       "      <td>-3.273502e-01</td>\n",
       "      <td>-8.279161e-01</td>\n",
       "      <td>-5.674703e+00</td>\n",
       "      <td>-4.105578e+00</td>\n",
       "      <td>-1.273562e+02</td>\n",
       "      <td>-1.313739e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.694473e-01</td>\n",
       "      <td>-9.930190e-01</td>\n",
       "      <td>-5.811941e-01</td>\n",
       "      <td>-2.456546e-01</td>\n",
       "      <td>-2.150536e-01</td>\n",
       "      <td>-4.066311e-01</td>\n",
       "      <td>-4.036219e-01</td>\n",
       "      <td>-6.645491e-01</td>\n",
       "      <td>-4.499059e-01</td>\n",
       "      <td>-2.883189e-01</td>\n",
       "      <td>-2.656320e-01</td>\n",
       "      <td>-1.194590e+00</td>\n",
       "      <td>-3.273502e-01</td>\n",
       "      <td>-3.930541e-01</td>\n",
       "      <td>-7.110487e-01</td>\n",
       "      <td>-3.165300e-01</td>\n",
       "      <td>-4.933499e-01</td>\n",
       "      <td>-3.765930e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.123358e-01</td>\n",
       "      <td>-5.187059e-02</td>\n",
       "      <td>-4.576034e-03</td>\n",
       "      <td>1.729394e-01</td>\n",
       "      <td>1.844283e-01</td>\n",
       "      <td>-1.341285e-01</td>\n",
       "      <td>-7.514916e-02</td>\n",
       "      <td>-1.938211e-01</td>\n",
       "      <td>-9.239435e-02</td>\n",
       "      <td>3.009278e-01</td>\n",
       "      <td>1.743898e-01</td>\n",
       "      <td>2.485268e-01</td>\n",
       "      <td>-1.871398e-01</td>\n",
       "      <td>-1.031461e-01</td>\n",
       "      <td>-2.860562e-01</td>\n",
       "      <td>1.748325e-01</td>\n",
       "      <td>3.079122e-02</td>\n",
       "      <td>9.430478e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.062635e-01</td>\n",
       "      <td>8.857128e-01</td>\n",
       "      <td>5.880592e-01</td>\n",
       "      <td>4.773714e-01</td>\n",
       "      <td>4.833294e-01</td>\n",
       "      <td>2.800755e-01</td>\n",
       "      <td>3.190181e-01</td>\n",
       "      <td>4.480808e-01</td>\n",
       "      <td>3.382445e-01</td>\n",
       "      <td>6.544757e-01</td>\n",
       "      <td>5.069644e-01</td>\n",
       "      <td>6.788382e-01</td>\n",
       "      <td>9.328095e-02</td>\n",
       "      <td>2.350799e-01</td>\n",
       "      <td>5.353222e-01</td>\n",
       "      <td>5.594320e-01</td>\n",
       "      <td>5.328688e-01</td>\n",
       "      <td>5.202980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.791083e+00</td>\n",
       "      <td>2.169097e+00</td>\n",
       "      <td>5.104901e+00</td>\n",
       "      <td>5.734260e+00</td>\n",
       "      <td>5.818658e+00</td>\n",
       "      <td>1.712482e+02</td>\n",
       "      <td>1.287894e+02</td>\n",
       "      <td>9.541691e+00</td>\n",
       "      <td>6.480942e+00</td>\n",
       "      <td>1.553077e+00</td>\n",
       "      <td>2.932201e+00</td>\n",
       "      <td>4.053109e+00</td>\n",
       "      <td>1.875546e+02</td>\n",
       "      <td>5.628396e+01</td>\n",
       "      <td>5.913651e+00</td>\n",
       "      <td>1.889007e+01</td>\n",
       "      <td>3.766221e+00</td>\n",
       "      <td>9.068616e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 GP       Min_per           usg           eFG        TS_per  \\\n",
       "count  6.101600e+04  6.101600e+04  6.101600e+04  6.101600e+04  6.101600e+04   \n",
       "mean   5.962336e-17  2.198611e-16  7.182751e-16  3.363130e-16  8.943504e-17   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -2.148194e+00 -1.324560e+00 -2.903684e+00 -2.420169e+00 -2.705139e+00   \n",
       "25%   -7.694473e-01 -9.930190e-01 -5.811941e-01 -2.456546e-01 -2.150536e-01   \n",
       "50%    4.123358e-01 -5.187059e-02 -4.576034e-03  1.729394e-01  1.844283e-01   \n",
       "75%    8.062635e-01  8.857128e-01  5.880592e-01  4.773714e-01  4.833294e-01   \n",
       "max    1.791083e+00  2.169097e+00  5.104901e+00  5.734260e+00  5.818658e+00   \n",
       "\n",
       "            ORB_per       DRB_per       AST_per        TO_per        FT_per  \\\n",
       "count  6.101600e+04  6.101600e+04  6.101600e+04  6.101600e+04  6.101600e+04   \n",
       "mean   2.748264e-17 -1.695539e-16 -4.564913e-17 -1.117938e-16 -4.341326e-16   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -6.028329e-01 -1.191956e+00 -1.156674e+00 -1.644319e+00 -2.129715e+00   \n",
       "25%   -4.066311e-01 -4.036219e-01 -6.645491e-01 -4.499059e-01 -2.883189e-01   \n",
       "50%   -1.341285e-01 -7.514916e-02 -1.938211e-01 -9.239435e-02  3.009278e-01   \n",
       "75%    2.800755e-01  3.190181e-01  4.480808e-01  3.382445e-01  6.544757e-01   \n",
       "max    1.712482e+02  1.287894e+02  9.541691e+00  6.480942e+00  1.553077e+00   \n",
       "\n",
       "           twoP_per        TP_per       blk_per       stl_per        porpag  \\\n",
       "count  6.101600e+04  6.101600e+04  6.101600e+04  6.101600e+04  6.101600e+04   \n",
       "mean   6.614466e-17 -5.543109e-17  1.164519e-18 -3.330524e-17  4.099106e-17   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -2.184332e+00 -1.194590e+00 -3.273502e-01 -8.279161e-01 -5.674703e+00   \n",
       "25%   -2.656320e-01 -1.194590e+00 -3.273502e-01 -3.930541e-01 -7.110487e-01   \n",
       "50%    1.743898e-01  2.485268e-01 -1.871398e-01 -1.031461e-01 -2.860562e-01   \n",
       "75%    5.069644e-01  6.788382e-01  9.328095e-02  2.350799e-01  5.353222e-01   \n",
       "max    2.932201e+00  4.053109e+00  1.875546e+02  5.628396e+01  5.913651e+00   \n",
       "\n",
       "              adjoe         adrtg           bpm  \n",
       "count  6.101600e+04  6.101600e+04  6.101600e+04  \n",
       "mean  -4.844398e-17  1.109321e-15 -3.912783e-17  \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  \n",
       "min   -4.105578e+00 -1.273562e+02 -1.313739e+01  \n",
       "25%   -3.165300e-01 -4.933499e-01 -3.765930e-01  \n",
       "50%    1.748325e-01  3.079122e-02  9.430478e-02  \n",
       "75%    5.594320e-01  5.328688e-01  5.202980e-01  \n",
       "max    1.889007e+01  3.766221e+00  9.068616e+01  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe features\n",
    "clean_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sadrži 61016 odbiraka, od čega su 2.35% pozitivni.\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage of True datapoints\n",
    "value_cnts = clean_df[\"Target\"].value_counts()\n",
    "print(f\"Dataset sadrži {len(clean_df)} odbiraka, od čega su {value_cnts[True] / len(clean_df) * 100:0.2f}% pozitivni.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>AST_per</th>\n",
       "      <th>TO_per</th>\n",
       "      <th>FT_per</th>\n",
       "      <th>twoP_per</th>\n",
       "      <th>TP_per</th>\n",
       "      <th>blk_per</th>\n",
       "      <th>stl_per</th>\n",
       "      <th>porpag</th>\n",
       "      <th>adjoe</th>\n",
       "      <th>adrtg</th>\n",
       "      <th>bpm</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.765820</td>\n",
       "      <td>0.194050</td>\n",
       "      <td>0.409923</td>\n",
       "      <td>0.427681</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.192817</td>\n",
       "      <td>-0.034862</td>\n",
       "      <td>0.585025</td>\n",
       "      <td>0.414662</td>\n",
       "      <td>0.304386</td>\n",
       "      <td>0.039081</td>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.483579</td>\n",
       "      <td>0.487660</td>\n",
       "      <td>-0.146277</td>\n",
       "      <td>0.461438</td>\n",
       "      <td>0.024946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Min_per</th>\n",
       "      <td>0.765820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.349595</td>\n",
       "      <td>0.348403</td>\n",
       "      <td>0.380544</td>\n",
       "      <td>-0.052275</td>\n",
       "      <td>0.036532</td>\n",
       "      <td>0.336854</td>\n",
       "      <td>-0.113360</td>\n",
       "      <td>0.552844</td>\n",
       "      <td>0.327512</td>\n",
       "      <td>0.371083</td>\n",
       "      <td>-0.010379</td>\n",
       "      <td>0.080611</td>\n",
       "      <td>0.708881</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>-0.064984</td>\n",
       "      <td>0.443473</td>\n",
       "      <td>0.020441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usg</th>\n",
       "      <td>0.194050</td>\n",
       "      <td>0.349595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167070</td>\n",
       "      <td>0.212859</td>\n",
       "      <td>0.093885</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>0.284138</td>\n",
       "      <td>0.089828</td>\n",
       "      <td>0.304460</td>\n",
       "      <td>0.179131</td>\n",
       "      <td>0.182168</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.436231</td>\n",
       "      <td>0.364998</td>\n",
       "      <td>-0.092023</td>\n",
       "      <td>-0.017766</td>\n",
       "      <td>0.012508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eFG</th>\n",
       "      <td>0.409923</td>\n",
       "      <td>0.348403</td>\n",
       "      <td>0.167070</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933809</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>0.061065</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>0.336464</td>\n",
       "      <td>0.727813</td>\n",
       "      <td>0.448794</td>\n",
       "      <td>0.055098</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.421684</td>\n",
       "      <td>0.772254</td>\n",
       "      <td>-0.080664</td>\n",
       "      <td>0.482291</td>\n",
       "      <td>0.010164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS_per</th>\n",
       "      <td>0.427681</td>\n",
       "      <td>0.380544</td>\n",
       "      <td>0.212859</td>\n",
       "      <td>0.933809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>0.057344</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>-0.053406</td>\n",
       "      <td>0.491049</td>\n",
       "      <td>0.676865</td>\n",
       "      <td>0.452119</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.462121</td>\n",
       "      <td>0.844409</td>\n",
       "      <td>-0.080948</td>\n",
       "      <td>0.501096</td>\n",
       "      <td>0.010287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORB_per</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.052275</td>\n",
       "      <td>0.093885</td>\n",
       "      <td>0.043225</td>\n",
       "      <td>0.033404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508856</td>\n",
       "      <td>-0.122554</td>\n",
       "      <td>-0.024485</td>\n",
       "      <td>-0.051092</td>\n",
       "      <td>0.088298</td>\n",
       "      <td>-0.154237</td>\n",
       "      <td>0.630562</td>\n",
       "      <td>0.130582</td>\n",
       "      <td>0.026619</td>\n",
       "      <td>0.132315</td>\n",
       "      <td>-0.449782</td>\n",
       "      <td>0.328274</td>\n",
       "      <td>0.005307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRB_per</th>\n",
       "      <td>0.037879</td>\n",
       "      <td>0.036532</td>\n",
       "      <td>0.096105</td>\n",
       "      <td>0.061065</td>\n",
       "      <td>0.057344</td>\n",
       "      <td>0.508856</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072565</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>0.094974</td>\n",
       "      <td>-0.079822</td>\n",
       "      <td>0.571872</td>\n",
       "      <td>0.095521</td>\n",
       "      <td>0.076094</td>\n",
       "      <td>0.069541</td>\n",
       "      <td>-0.595881</td>\n",
       "      <td>0.202997</td>\n",
       "      <td>0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST_per</th>\n",
       "      <td>0.192817</td>\n",
       "      <td>0.336854</td>\n",
       "      <td>0.284138</td>\n",
       "      <td>0.077824</td>\n",
       "      <td>0.106743</td>\n",
       "      <td>-0.122554</td>\n",
       "      <td>-0.072565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061244</td>\n",
       "      <td>0.212607</td>\n",
       "      <td>0.051719</td>\n",
       "      <td>0.252085</td>\n",
       "      <td>-0.103963</td>\n",
       "      <td>0.174392</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>0.250201</td>\n",
       "      <td>-0.023550</td>\n",
       "      <td>0.207522</td>\n",
       "      <td>0.005954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TO_per</th>\n",
       "      <td>-0.034862</td>\n",
       "      <td>-0.113360</td>\n",
       "      <td>0.089828</td>\n",
       "      <td>-0.057194</td>\n",
       "      <td>-0.053406</td>\n",
       "      <td>-0.024485</td>\n",
       "      <td>-0.001328</td>\n",
       "      <td>0.061244</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>-0.040603</td>\n",
       "      <td>-0.086372</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>-0.261359</td>\n",
       "      <td>-0.264230</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.273051</td>\n",
       "      <td>-0.002574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT_per</th>\n",
       "      <td>0.585025</td>\n",
       "      <td>0.552844</td>\n",
       "      <td>0.304460</td>\n",
       "      <td>0.336464</td>\n",
       "      <td>0.491049</td>\n",
       "      <td>-0.051092</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>0.212607</td>\n",
       "      <td>-0.058595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.336598</td>\n",
       "      <td>0.347202</td>\n",
       "      <td>-0.020988</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.445305</td>\n",
       "      <td>0.540593</td>\n",
       "      <td>-0.039430</td>\n",
       "      <td>0.361276</td>\n",
       "      <td>0.008312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twoP_per</th>\n",
       "      <td>0.414662</td>\n",
       "      <td>0.327512</td>\n",
       "      <td>0.179131</td>\n",
       "      <td>0.727813</td>\n",
       "      <td>0.676865</td>\n",
       "      <td>0.088298</td>\n",
       "      <td>0.094974</td>\n",
       "      <td>0.051719</td>\n",
       "      <td>-0.040603</td>\n",
       "      <td>0.336598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094337</td>\n",
       "      <td>0.080301</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.354915</td>\n",
       "      <td>0.597451</td>\n",
       "      <td>-0.111654</td>\n",
       "      <td>0.402288</td>\n",
       "      <td>0.010562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TP_per</th>\n",
       "      <td>0.304386</td>\n",
       "      <td>0.371083</td>\n",
       "      <td>0.182168</td>\n",
       "      <td>0.448794</td>\n",
       "      <td>0.452119</td>\n",
       "      <td>-0.154237</td>\n",
       "      <td>-0.079822</td>\n",
       "      <td>0.252085</td>\n",
       "      <td>-0.086372</td>\n",
       "      <td>0.347202</td>\n",
       "      <td>0.094337</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.111076</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.358493</td>\n",
       "      <td>0.437625</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.285982</td>\n",
       "      <td>0.004773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blk_per</th>\n",
       "      <td>0.039081</td>\n",
       "      <td>-0.010379</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.055098</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.630562</td>\n",
       "      <td>0.571872</td>\n",
       "      <td>-0.103963</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>-0.020988</td>\n",
       "      <td>0.080301</td>\n",
       "      <td>-0.111076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.139131</td>\n",
       "      <td>0.013137</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>-0.572037</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.005447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stl_per</th>\n",
       "      <td>0.046268</td>\n",
       "      <td>0.080611</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.019267</td>\n",
       "      <td>0.130582</td>\n",
       "      <td>0.095521</td>\n",
       "      <td>0.174392</td>\n",
       "      <td>0.032145</td>\n",
       "      <td>0.052886</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.139131</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065283</td>\n",
       "      <td>0.050094</td>\n",
       "      <td>-0.515739</td>\n",
       "      <td>0.421497</td>\n",
       "      <td>0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>porpag</th>\n",
       "      <td>0.483579</td>\n",
       "      <td>0.708881</td>\n",
       "      <td>0.436231</td>\n",
       "      <td>0.421684</td>\n",
       "      <td>0.462121</td>\n",
       "      <td>0.026619</td>\n",
       "      <td>0.076094</td>\n",
       "      <td>0.279300</td>\n",
       "      <td>-0.261359</td>\n",
       "      <td>0.445305</td>\n",
       "      <td>0.354915</td>\n",
       "      <td>0.358493</td>\n",
       "      <td>0.013137</td>\n",
       "      <td>0.065283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643394</td>\n",
       "      <td>-0.190967</td>\n",
       "      <td>0.522151</td>\n",
       "      <td>0.033648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjoe</th>\n",
       "      <td>0.487660</td>\n",
       "      <td>0.486015</td>\n",
       "      <td>0.364998</td>\n",
       "      <td>0.772254</td>\n",
       "      <td>0.844409</td>\n",
       "      <td>0.132315</td>\n",
       "      <td>0.069541</td>\n",
       "      <td>0.250201</td>\n",
       "      <td>-0.264230</td>\n",
       "      <td>0.540593</td>\n",
       "      <td>0.597451</td>\n",
       "      <td>0.437625</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.050094</td>\n",
       "      <td>0.643394</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.146936</td>\n",
       "      <td>0.595765</td>\n",
       "      <td>0.019596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adrtg</th>\n",
       "      <td>-0.146277</td>\n",
       "      <td>-0.064984</td>\n",
       "      <td>-0.092023</td>\n",
       "      <td>-0.080664</td>\n",
       "      <td>-0.080948</td>\n",
       "      <td>-0.449782</td>\n",
       "      <td>-0.595881</td>\n",
       "      <td>-0.023550</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.039430</td>\n",
       "      <td>-0.111654</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>-0.572037</td>\n",
       "      <td>-0.515739</td>\n",
       "      <td>-0.190967</td>\n",
       "      <td>-0.146936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.562462</td>\n",
       "      <td>-0.014159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpm</th>\n",
       "      <td>0.461438</td>\n",
       "      <td>0.443473</td>\n",
       "      <td>-0.017766</td>\n",
       "      <td>0.482291</td>\n",
       "      <td>0.501096</td>\n",
       "      <td>0.328274</td>\n",
       "      <td>0.202997</td>\n",
       "      <td>0.207522</td>\n",
       "      <td>-0.273051</td>\n",
       "      <td>0.361276</td>\n",
       "      <td>0.402288</td>\n",
       "      <td>0.285982</td>\n",
       "      <td>0.429630</td>\n",
       "      <td>0.421497</td>\n",
       "      <td>0.522151</td>\n",
       "      <td>0.595765</td>\n",
       "      <td>-0.562462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <td>0.024946</td>\n",
       "      <td>0.020441</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>-0.002574</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.033648</td>\n",
       "      <td>0.019596</td>\n",
       "      <td>-0.014159</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                GP   Min_per       usg       eFG    TS_per   ORB_per  \\\n",
       "GP        1.000000  0.765820  0.194050  0.409923  0.427681  0.000044   \n",
       "Min_per   0.765820  1.000000  0.349595  0.348403  0.380544 -0.052275   \n",
       "usg       0.194050  0.349595  1.000000  0.167070  0.212859  0.093885   \n",
       "eFG       0.409923  0.348403  0.167070  1.000000  0.933809  0.043225   \n",
       "TS_per    0.427681  0.380544  0.212859  0.933809  1.000000  0.033404   \n",
       "ORB_per   0.000044 -0.052275  0.093885  0.043225  0.033404  1.000000   \n",
       "DRB_per   0.037879  0.036532  0.096105  0.061065  0.057344  0.508856   \n",
       "AST_per   0.192817  0.336854  0.284138  0.077824  0.106743 -0.122554   \n",
       "TO_per   -0.034862 -0.113360  0.089828 -0.057194 -0.053406 -0.024485   \n",
       "FT_per    0.585025  0.552844  0.304460  0.336464  0.491049 -0.051092   \n",
       "twoP_per  0.414662  0.327512  0.179131  0.727813  0.676865  0.088298   \n",
       "TP_per    0.304386  0.371083  0.182168  0.448794  0.452119 -0.154237   \n",
       "blk_per   0.039081 -0.010379  0.000179  0.055098  0.040541  0.630562   \n",
       "stl_per   0.046268  0.080611  0.097729  0.006074  0.019267  0.130582   \n",
       "porpag    0.483579  0.708881  0.436231  0.421684  0.462121  0.026619   \n",
       "adjoe     0.487660  0.486015  0.364998  0.772254  0.844409  0.132315   \n",
       "adrtg    -0.146277 -0.064984 -0.092023 -0.080664 -0.080948 -0.449782   \n",
       "bpm       0.461438  0.443473 -0.017766  0.482291  0.501096  0.328274   \n",
       "Target    0.024946  0.020441  0.012508  0.010164  0.010287  0.005307   \n",
       "\n",
       "           DRB_per   AST_per    TO_per    FT_per  twoP_per    TP_per  \\\n",
       "GP        0.037879  0.192817 -0.034862  0.585025  0.414662  0.304386   \n",
       "Min_per   0.036532  0.336854 -0.113360  0.552844  0.327512  0.371083   \n",
       "usg       0.096105  0.284138  0.089828  0.304460  0.179131  0.182168   \n",
       "eFG       0.061065  0.077824 -0.057194  0.336464  0.727813  0.448794   \n",
       "TS_per    0.057344  0.106743 -0.053406  0.491049  0.676865  0.452119   \n",
       "ORB_per   0.508856 -0.122554 -0.024485 -0.051092  0.088298 -0.154237   \n",
       "DRB_per   1.000000 -0.072565 -0.001328 -0.001392  0.094974 -0.079822   \n",
       "AST_per  -0.072565  1.000000  0.061244  0.212607  0.051719  0.252085   \n",
       "TO_per   -0.001328  0.061244  1.000000 -0.058595 -0.040603 -0.086372   \n",
       "FT_per   -0.001392  0.212607 -0.058595  1.000000  0.336598  0.347202   \n",
       "twoP_per  0.094974  0.051719 -0.040603  0.336598  1.000000  0.094337   \n",
       "TP_per   -0.079822  0.252085 -0.086372  0.347202  0.094337  1.000000   \n",
       "blk_per   0.571872 -0.103963  0.000630 -0.020988  0.080301 -0.111076   \n",
       "stl_per   0.095521  0.174392  0.032145  0.052886  0.021188  0.055295   \n",
       "porpag    0.076094  0.279300 -0.261359  0.445305  0.354915  0.358493   \n",
       "adjoe     0.069541  0.250201 -0.264230  0.540593  0.597451  0.437625   \n",
       "adrtg    -0.595881 -0.023550 -0.000020 -0.039430 -0.111654  0.029484   \n",
       "bpm       0.202997  0.207522 -0.273051  0.361276  0.402288  0.285982   \n",
       "Target    0.004004  0.005954 -0.002574  0.008312  0.010562  0.004773   \n",
       "\n",
       "           blk_per   stl_per    porpag     adjoe     adrtg       bpm    Target  \n",
       "GP        0.039081  0.046268  0.483579  0.487660 -0.146277  0.461438  0.024946  \n",
       "Min_per  -0.010379  0.080611  0.708881  0.486015 -0.064984  0.443473  0.020441  \n",
       "usg       0.000179  0.097729  0.436231  0.364998 -0.092023 -0.017766  0.012508  \n",
       "eFG       0.055098  0.006074  0.421684  0.772254 -0.080664  0.482291  0.010164  \n",
       "TS_per    0.040541  0.019267  0.462121  0.844409 -0.080948  0.501096  0.010287  \n",
       "ORB_per   0.630562  0.130582  0.026619  0.132315 -0.449782  0.328274  0.005307  \n",
       "DRB_per   0.571872  0.095521  0.076094  0.069541 -0.595881  0.202997  0.004004  \n",
       "AST_per  -0.103963  0.174392  0.279300  0.250201 -0.023550  0.207522  0.005954  \n",
       "TO_per    0.000630  0.032145 -0.261359 -0.264230 -0.000020 -0.273051 -0.002574  \n",
       "FT_per   -0.020988  0.052886  0.445305  0.540593 -0.039430  0.361276  0.008312  \n",
       "twoP_per  0.080301  0.021188  0.354915  0.597451 -0.111654  0.402288  0.010562  \n",
       "TP_per   -0.111076  0.055295  0.358493  0.437625  0.029484  0.285982  0.004773  \n",
       "blk_per   1.000000  0.139131  0.013137  0.032016 -0.572037  0.429630  0.005447  \n",
       "stl_per   0.139131  1.000000  0.065283  0.050094 -0.515739  0.421497  0.003452  \n",
       "porpag    0.013137  0.065283  1.000000  0.643394 -0.190967  0.522151  0.033648  \n",
       "adjoe     0.032016  0.050094  0.643394  1.000000 -0.146936  0.595765  0.019596  \n",
       "adrtg    -0.572037 -0.515739 -0.190967 -0.146936  1.000000 -0.562462 -0.014159  \n",
       "bpm       0.429630  0.421497  0.522151  0.595765 -0.562462  1.000000  0.019177  \n",
       "Target    0.005447  0.003452  0.033648  0.019596 -0.014159  0.019177  1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = clean_df.corr().to_numpy()[:-1, :-1]\n",
    "\n",
    "# Calculate eig\n",
    "eigen_values, eigen_vectors = np.linalg.eigh(cov_mat)\n",
    "\n",
    "# Sort indexes\n",
    "\n",
    "# Take vector subset\n",
    "num_of_components = 5\n",
    "eigv_subset = eigen_vectors[:, -num_of_components:]\n",
    "\n",
    "# # Reduce X\n",
    "# X_reduced = np.dot(eigv_subset.T, X.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61016, 5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = clean_df.to_numpy()[:, :-1]\n",
    "\n",
    "X_reduced = np.dot(eigv_subset.T, X.T).T\n",
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.151748</td>\n",
       "      <td>0.426638</td>\n",
       "      <td>0.270746</td>\n",
       "      <td>1.098903</td>\n",
       "      <td>0.222516</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.483462</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>-1.466385</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.69801</td>\n",
       "      <td>0.203203</td>\n",
       "      <td>0.926932</td>\n",
       "      <td>0.920432</td>\n",
       "      <td>-1.439232</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.583241</td>\n",
       "      <td>0.251604</td>\n",
       "      <td>0.013704</td>\n",
       "      <td>0.68152</td>\n",
       "      <td>-0.660514</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.660798</td>\n",
       "      <td>-0.877505</td>\n",
       "      <td>-0.216661</td>\n",
       "      <td>-0.436325</td>\n",
       "      <td>-0.961933</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61011</th>\n",
       "      <td>-6.213614</td>\n",
       "      <td>4.241152</td>\n",
       "      <td>6.932279</td>\n",
       "      <td>-3.721636</td>\n",
       "      <td>2.765088</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61012</th>\n",
       "      <td>-0.05206</td>\n",
       "      <td>-0.436786</td>\n",
       "      <td>0.243023</td>\n",
       "      <td>0.42146</td>\n",
       "      <td>6.650603</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61013</th>\n",
       "      <td>1.122304</td>\n",
       "      <td>3.291919</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>-0.250891</td>\n",
       "      <td>6.428082</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61014</th>\n",
       "      <td>1.056305</td>\n",
       "      <td>3.479652</td>\n",
       "      <td>0.150621</td>\n",
       "      <td>-0.385733</td>\n",
       "      <td>6.255471</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61015</th>\n",
       "      <td>-0.515027</td>\n",
       "      <td>0.835971</td>\n",
       "      <td>2.425438</td>\n",
       "      <td>0.573528</td>\n",
       "      <td>1.712784</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61016 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             f0        f1        f2        f3        f4  Target\n",
       "0     -0.151748  0.426638  0.270746  1.098903  0.222516   False\n",
       "1      0.097561  0.483462  0.066349    0.8777 -1.466385   False\n",
       "2       0.69801  0.203203  0.926932  0.920432 -1.439232   False\n",
       "3     -0.583241  0.251604  0.013704   0.68152 -0.660514   False\n",
       "4      0.660798 -0.877505 -0.216661 -0.436325 -0.961933   False\n",
       "...         ...       ...       ...       ...       ...     ...\n",
       "61011 -6.213614  4.241152  6.932279 -3.721636  2.765088   False\n",
       "61012  -0.05206 -0.436786  0.243023   0.42146  6.650603   False\n",
       "61013  1.122304  3.291919  0.131148 -0.250891  6.428082   False\n",
       "61014  1.056305  3.479652  0.150621 -0.385733  6.255471   False\n",
       "61015 -0.515027  0.835971  2.425438  0.573528  1.712784   False\n",
       "\n",
       "[61016 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df = pd.DataFrame(X_reduced, columns=[f\"f{idx}\" for idx in range(num_of_components)])\n",
    "reduced_df[\"Target\"] = clean_df[\"Target\"]\n",
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podela na trening i test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Do train/test split\n",
    "train_df, valid_df = train_test_split(reduced_df, train_size=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(clean_df)\n",
    "# clean_np = scaler.transform(clean_df)\n",
    "\n",
    "# clean_df = pd.DataFrame(clean_np, columns=clean_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definisanje modela\n",
    "\n",
    "Model će se sastojati od duboke neuronske mreže, sa potpuno povezanim slojevima.\n",
    "Ulaz u mrežu će biti prethodno izabrani atributi, a izlaz će sadžati jedan neuron čiji izlaz predstavlja uverenost modela da će ulazni igrač biti NBA pik.\n",
    "\n",
    "#### Dataset klasa\n",
    "\n",
    "Prvi korak predstavlja definisanje klase koja će dohvatati podatke u _batch_-evima tokom treniranja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NBA_Dataset(Dataset):\n",
    "    \"\"\"Class for holding data of NCAA players and if there were picked for the NBA.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Initialize torch Dataset based on pandas Dataframe.\"\"\"\n",
    "        super(NBA_Dataset, self).__init__()\n",
    "\n",
    "        # Take all except the last column as inputs\n",
    "        self.inputs = df.values[:, :-1].astype(float)\n",
    "\n",
    "        # Cast Targets column to numpy\n",
    "        self.targets = df[\"Target\"].values.astype(int)\n",
    "\n",
    "        # Save dataframe as part of the class\n",
    "        self.df = df\n",
    "\n",
    "        # Define dataset length\n",
    "        self.len = len(df)\n",
    "\n",
    "    def __getitem__(self, index) -> dict:\n",
    "        \"\"\"Return dict with information of datapoint at `index`\"\"\"\n",
    "        # Get input\n",
    "        input_row = torch.Tensor(self.inputs[index, :])\n",
    "\n",
    "        # Get output\n",
    "        target = torch.Tensor([self.targets[index]])\n",
    "\n",
    "        return {\n",
    "            \"Inputs\": input_row,\n",
    "            \"Targets\": target,\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get dataset length.\"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definicija modela\n",
    "\n",
    "**OVDE SE PISE O TOME STA SVE IMA U MODELU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NBA_Draft_Predictor(nn.Module):\n",
    "    \"\"\"Class for prediction NCAA player chances of being piked in NBA draft.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes: list, activation_function: nn.Module = None) -> None:\n",
    "        \"\"\"Initialize fully-connected model based on input parameters.\"\"\"\n",
    "        super(NBA_Draft_Predictor, self).__init__()\n",
    "\n",
    "        assert len(layer_sizes)\n",
    "\n",
    "        # Check if activation function is not defined\n",
    "        if activation_function is None:\n",
    "            activation_function = nn.ReLU()\n",
    "\n",
    "        # Define activation function\n",
    "        self.activation = activation_function\n",
    "\n",
    "        # Layers init\n",
    "        layer_list = []\n",
    "\n",
    "        # Define layer sizes\n",
    "        for in_size, out_size in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            layer_list.append(nn.Linear(in_size, out_size))\n",
    "            # layer_list.append(nn.Tanh())\n",
    "\n",
    "        # Cast layer list to nn.Module\n",
    "        self.fc_layers = nn.ModuleList(layer_list)\n",
    "\n",
    "    def forward(self, X) -> torch.Tensor:\n",
    "        \"\"\"Define network behavior when called on data.\"\"\"\n",
    "        # Pass data trough fully-connected layers\n",
    "        for layer in self.fc_layers:\n",
    "            X = layer(X)\n",
    "        \n",
    "        # Calculate output probability as sigmoid of output\n",
    "        output_probability = torch.sigmoid(X)\n",
    "\n",
    "        return output_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "train_dataset = NBA_Dataset(train_df)\n",
    "\n",
    "train_parameters = {\n",
    "    \"batch_size\": 32,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 1,\n",
    "}\n",
    "\n",
    "# Initialize sampler\n",
    "\n",
    "value_counts = train_dataset.df[\"Target\"].value_counts()\n",
    "class_sample_count = np.array([value_cnts[False], value_cnts[True]])\n",
    "\n",
    "weight = 1. / class_sample_count\n",
    "\n",
    "samples_weight = torch.Tensor([weight[target] for target in train_dataset.targets])\n",
    "train_parameters[\"sampler\"] = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "\n",
    "training_loader = DataLoader(train_dataset, **train_parameters)\n",
    "\n",
    "# Validation dataset\n",
    "valid_dataset = NBA_Dataset(valid_df)\n",
    "\n",
    "train_parameters = {\n",
    "    \"batch_size\": 32,\n",
    "    \"shuffle\": False,\n",
    "    \"num_workers\": 1,\n",
    "}\n",
    "\n",
    "validation_loader = DataLoader(valid_dataset, **train_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicijalizacija treninga\n",
    "\n",
    "**Ovde objasniti zasto smo odabrali Adam optimajzer i BCE loss funkciju**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss, CrossEntropyLoss\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "# Initialize optimizer\n",
    "model = NBA_Draft_Predictor([train_dataset.inputs.shape[1], 10, 1])\n",
    "\n",
    "# Initialize loss function as Binary Cross Entropy\n",
    "loss_function = BCELoss()\n",
    "\n",
    "# Define learning rate\n",
    "lr = 1e-2\n",
    "\n",
    "# Init Adam optimizer\n",
    "optimizer = Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "# Classification threshold\n",
    "CLASS_THR = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started epoch 01\n",
      "Training loss: 0.6928773348697562\n",
      "Started epoch 02\n",
      "Training loss: 0.6937272744678826\n",
      "Started epoch 03\n",
      "Training loss: 0.6904895746306087\n",
      "Started epoch 04\n",
      "Training loss: 0.6916135743316193\n",
      "Started epoch 05\n",
      "Training loss: 0.6915789948420579\n",
      "Started epoch 06\n",
      "Training loss: 0.6914807060238127\n",
      "Started epoch 07\n",
      "Training loss: 0.6931431302417084\n",
      "Started epoch 08\n",
      "Training loss: 0.6959932861703165\n",
      "Started epoch 09\n",
      "Training loss: 0.6909679996833372\n",
      "Started epoch 10\n",
      "Training loss: 0.6930205219247368\n",
      "Started epoch 11\n",
      "Training loss: 0.6935990834057554\n",
      "Started epoch 12\n",
      "Training loss: 0.6916471388902558\n",
      "Started epoch 13\n",
      "Training loss: 0.6928305489740122\n",
      "Started epoch 14\n",
      "Training loss: 0.6951914938648095\n",
      "Started epoch 15\n",
      "Training loss: 0.6918489238742586\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"log.log\")\n",
    "\n",
    "num_of_epochs = 15\n",
    "\n",
    "training_loss = []\n",
    "\n",
    "validation_loss = []\n",
    "validation_prec = []\n",
    "validation_rec = []\n",
    "validation_f1 = []\n",
    "\n",
    "for epoch in range(1, num_of_epochs + 1):\n",
    "\n",
    "    print(f\"Started epoch {epoch:02}\")\n",
    "\n",
    "    # Run epoch of training\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in training_loader:\n",
    "        \n",
    "        # Load batch\n",
    "        X = batch[\"Inputs\"]\n",
    "        Y = batch[\"Targets\"]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Run forward pass\n",
    "        probabilities = model(X)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_function(probabilities, Y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Update model\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate predictions\n",
    "        predictions = probabilities >= CLASS_THR\n",
    "\n",
    "    epoch_loss /= len(training_loader)\n",
    "    print(f\"Training loss: {epoch_loss}\")\n",
    "\n",
    "\n",
    "    training_loss.append(epoch_loss)\n",
    "\n",
    "    # VALIDATION\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_predictions = []\n",
    "    epoch_targets = []\n",
    "\n",
    "    for batch in validation_loader:\n",
    "        \n",
    "        # Load batch\n",
    "        X = batch[\"Inputs\"]\n",
    "        Y = batch[\"Targets\"]\n",
    "\n",
    "        # Run forward pass\n",
    "        probabilities = model(X)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_function(probabilities, Y)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Update model\n",
    "        loss.backward()\n",
    "\n",
    "        # Calculate predictions\n",
    "        predictions = probabilities >= CLASS_THR\n",
    "\n",
    "        # Log predictions\n",
    "        epoch_predictions.extend(predictions.tolist())\n",
    "        epoch_targets.extend(Y.tolist())\n",
    "\n",
    "    epoch_loss /= len(training_loader)\n",
    "\n",
    "    validation_loss.append(epoch_loss)\n",
    "    \n",
    "    logging.info(epoch)\n",
    "    logging.info(classification_report(epoch_targets, epoch_predictions))\n",
    "\n",
    "    # Metrics\n",
    "    validation_prec.append(precision_score(epoch_targets, epoch_predictions))\n",
    "    validation_rec.append(recall_score(epoch_targets, epoch_predictions))\n",
    "    validation_f1.append(f1_score(epoch_targets, epoch_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fca43278ee0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_loss, label=\"Train\")\n",
    "plt.plot(validation_loss, label=\"Validation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fca432d2f70>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_prec, label=\"Precision\")\n",
    "plt.plot(validation_rec, label=\"Recall\")\n",
    "plt.plot(validation_f1, label=\"F1\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
